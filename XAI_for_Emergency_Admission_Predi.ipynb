{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 3419588,
          "sourceType": "datasetVersion",
          "datasetId": 2061039
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "XAI for Emergency Admission Predi",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gajeshgif/Gajesh/blob/main/XAI_for_Emergency_Admission_Predi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "asjad99_mimiciii_path = kagglehub.dataset_download('asjad99/mimiciii')\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "id": "sICj9dxlScYB"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T10:47:14.346476Z",
          "iopub.execute_input": "2025-05-20T10:47:14.346744Z",
          "iopub.status.idle": "2025-05-20T10:47:16.13823Z",
          "shell.execute_reply.started": "2025-05-20T10:47:14.346716Z",
          "shell.execute_reply": "2025-05-20T10:47:16.137295Z"
        },
        "id": "699u5H9wScYK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "admissions = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/ADMISSIONS.csv\")\n",
        "patients = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/PATIENTS.csv\")\n",
        "diagnoses = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/DIAGNOSES_ICD.csv\")\n",
        "\n",
        "# Show column names\n",
        "print(\"ADMISSIONS columns:\", admissions.columns.tolist())\n",
        "print(\"PATIENTS columns:\", patients.columns.tolist())\n",
        "print(\"DIAGNOSES columns:\", diagnoses.columns.tolist())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T10:50:51.972674Z",
          "iopub.execute_input": "2025-05-20T10:50:51.973023Z",
          "iopub.status.idle": "2025-05-20T10:50:51.99221Z",
          "shell.execute_reply.started": "2025-05-20T10:50:51.972999Z",
          "shell.execute_reply": "2025-05-20T10:50:51.991172Z"
        },
        "id": "cIHOkcJmScYQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load datasets\n",
        "admissions = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/ADMISSIONS.csv\")\n",
        "patients = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/PATIENTS.csv\")\n",
        "diagnoses = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/DIAGNOSES_ICD.csv\")\n",
        "\n",
        "# Ensure lowercase columns\n",
        "admissions.columns = admissions.columns.str.lower()\n",
        "patients.columns = patients.columns.str.lower()\n",
        "diagnoses.columns = diagnoses.columns.str.lower()\n",
        "\n",
        "# Merge\n",
        "df = pd.merge(admissions, patients, on='subject_id', how='inner')\n",
        "\n",
        "# Convert to datetime\n",
        "df['admittime'] = pd.to_datetime(df['admittime'], errors='coerce')\n",
        "df['dob'] = pd.to_datetime(df['dob'], errors='coerce')\n",
        "\n",
        "# Drop rows with missing/invalid dates\n",
        "df = df.dropna(subset=['admittime', 'dob'])\n",
        "\n",
        "# Remove date outliers to prevent overflow\n",
        "df = df[(df['dob'].dt.year >= 1900) & (df['dob'].dt.year <= 2025)]\n",
        "\n",
        "# Calculate admit age safely\n",
        "df['admit_age'] = (df['admittime'] - df['dob']).dt.total_seconds() / (365.25 * 24 * 3600)\n",
        "df['admit_age'] = df['admit_age'].clip(lower=0, upper=120)\n",
        "\n",
        "# Emergency admission label\n",
        "df['is_emergency'] = df['admission_type'].apply(lambda x: 1 if x == 'EMERGENCY' else 0)\n",
        "\n",
        "# EDA plots\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.countplot(data=df, x='admission_type', order=df['admission_type'].value_counts().index)\n",
        "plt.title(\"Admission Types\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.kdeplot(data=df, x='admit_age', hue='admission_type', common_norm=False, fill=True)\n",
        "plt.title(\"Age Distribution by Admission Type\")\n",
        "plt.xlabel(\"Age at Admission\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(data=df, x='gender')\n",
        "plt.title(\"Gender Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(data=df, x='gender', y='is_emergency')\n",
        "plt.title(\"Emergency Admission Rate by Gender\")\n",
        "plt.ylabel(\"Proportion Emergency\")\n",
        "plt.show()\n",
        "\n",
        "# Join number of diagnoses per admission\n",
        "diag_counts = diagnoses.groupby('hadm_id').size().reset_index(name='num_diag')\n",
        "df = pd.merge(df, diag_counts, on='hadm_id', how='left')\n",
        "df['num_diag'] = df['num_diag'].fillna(0)\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "sns.histplot(df['num_diag'], bins=30, kde=True)\n",
        "plt.title(\"Number of Diagnoses per Admission\")\n",
        "plt.xlabel(\"Number of Diagnoses\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "sns.boxplot(data=df, x='is_emergency', y='num_diag')\n",
        "plt.title(\"Diagnoses Count by Emergency Admission Status\")\n",
        "plt.xlabel(\"Is Emergency\")\n",
        "plt.ylabel(\"Number of Diagnoses\")\n",
        "plt.show()\n",
        "\n",
        "df['gender_enc'] = df['gender'].map({'M': 1, 'F': 0})\n",
        "corr_features = df[['admit_age', 'num_diag', 'is_emergency', 'gender_enc']]\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(corr_features.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title(\"Feature Correlation\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T10:54:20.377484Z",
          "iopub.execute_input": "2025-05-20T10:54:20.377787Z",
          "iopub.status.idle": "2025-05-20T10:54:21.802751Z",
          "shell.execute_reply.started": "2025-05-20T10:54:20.377768Z",
          "shell.execute_reply": "2025-05-20T10:54:21.801678Z"
        },
        "id": "7CjW7ot7ScYU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# 1. Import Libraries\n",
        "# ======================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import lightgbm as lgb\n",
        "import shap\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "shap.initjs()\n",
        "\n",
        "# ======================\n",
        "# 2. Load Datasets\n",
        "# ======================\n",
        "admissions = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/ADMISSIONS.csv\")\n",
        "patients = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/PATIENTS.csv\")\n",
        "diagnoses = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/DIAGNOSES_ICD.csv\")\n",
        "labs = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/LABEVENTS.csv\")  # Full load\n",
        "\n",
        "# Standardize column names\n",
        "admissions.columns = admissions.columns.str.lower()\n",
        "patients.columns = patients.columns.str.lower()\n",
        "diagnoses.columns = diagnoses.columns.str.lower()\n",
        "labs.columns = labs.columns.str.lower()\n",
        "\n",
        "# ======================\n",
        "# 3. Merge & Feature Engineering\n",
        "# ======================\n",
        "df = pd.merge(admissions, patients, on='subject_id', how='inner')\n",
        "\n",
        "# Convert datetime columns\n",
        "df['admittime'] = pd.to_datetime(df['admittime'], errors='coerce')\n",
        "df['dob'] = pd.to_datetime(df['dob'], errors='coerce')\n",
        "\n",
        "# Drop rows with invalid dates\n",
        "df = df.dropna(subset=['admittime', 'dob'])\n",
        "\n",
        "# Relaxed DOB filtering to allow synthetic dates up to year 2200\n",
        "df = df[(df['dob'].dt.year >= 1900) & (df['dob'].dt.year <= 2200)]\n",
        "\n",
        "# Check if enough rows remain\n",
        "if df.shape[0] < 10:\n",
        "    raise ValueError(f\"Too few rows after filtering. Only {df.shape[0]} rows.\")\n",
        "\n",
        "# Target variable: emergency admission = 1 else 0\n",
        "df['emergency_label'] = df['admission_type'].apply(lambda x: 1 if x == 'EMERGENCY' else 0)\n",
        "\n",
        "# Calculate age at admission (years)\n",
        "df['admit_age'] = (df['admittime'] - df['dob']).dt.total_seconds() / (365.25 * 24 * 3600)\n",
        "df['admit_age'] = df['admit_age'].clip(lower=0, upper=120)\n",
        "\n",
        "# Diagnosis count per hospital admission\n",
        "diag_count = diagnoses.groupby('hadm_id').size().reset_index(name='num_diag')\n",
        "df = pd.merge(df, diag_count, on='hadm_id', how='left')\n",
        "df['num_diag'].fillna(0, inplace=True)\n",
        "\n",
        "# Lab events count per hospital admission\n",
        "lab_count = labs.groupby('hadm_id').size().reset_index(name='num_labs')\n",
        "df = pd.merge(df, lab_count, on='hadm_id', how='left')\n",
        "df['num_labs'].fillna(0, inplace=True)\n",
        "\n",
        "# Encode gender as numeric\n",
        "df['gender'] = LabelEncoder().fit_transform(df['gender'])\n",
        "\n",
        "# ======================\n",
        "# 4. Prepare Data\n",
        "# ======================\n",
        "features = ['gender', 'admit_age', 'num_diag', 'num_labs']\n",
        "X = df[features]\n",
        "y = df['emergency_label']\n",
        "\n",
        "# Check if dataset has enough rows to split\n",
        "if X.shape[0] < 2:\n",
        "    raise ValueError(f\"Not enough samples to train/test split: only {X.shape[0]} rows.\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, stratify=y, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "# ======================\n",
        "# 5. Train LightGBM Model\n",
        "# ======================\n",
        "model = lgb.LGBMClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict & evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(f\"AUC Score: {roc_auc_score(y_test, y_prob):.4f}\")\n",
        "\n",
        "# ======================\n",
        "# 6. Feature Importance Plot\n",
        "# ======================\n",
        "lgb.plot_importance(model, importance_type='gain', figsize=(10, 6))\n",
        "plt.title(\"LightGBM Feature Importance (Gain)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ======================\n",
        "# 7. SHAP XAI Visualization\n",
        "# ======================\n",
        "explainer = shap.Explainer(model, X_train)\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "# SHAP summary plot\n",
        "shap.summary_plot(shap_values, X_test)\n",
        "\n",
        "# SHAP waterfall plot for the first test instance\n",
        "shap.plots.waterfall(shap_values[0])\n",
        "\n",
        "# ======================\n",
        "# 8. Correlation Heatmap\n",
        "# ======================\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(X.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T11:05:00.967987Z",
          "iopub.execute_input": "2025-05-20T11:05:00.968352Z",
          "iopub.status.idle": "2025-05-20T11:05:02.590022Z",
          "shell.execute_reply.started": "2025-05-20T11:05:00.968325Z",
          "shell.execute_reply": "2025-05-20T11:05:02.588836Z"
        },
        "id": "iNrR0n86ScYY"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}