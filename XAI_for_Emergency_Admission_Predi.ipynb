{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 3419588,
          "sourceType": "datasetVersion",
          "datasetId": 2061039
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "XAI for Emergency Admission Predi",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gajeshgif/Gajesh/blob/main/XAI_for_Emergency_Admission_Predi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "asjad99_mimiciii_path = kagglehub.dataset_download('asjad99/mimiciii')\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "id": "pf_8UyH4WNXk"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T12:07:46.728585Z",
          "iopub.execute_input": "2025-05-21T12:07:46.728863Z",
          "iopub.status.idle": "2025-05-21T12:07:47.102661Z",
          "shell.execute_reply.started": "2025-05-21T12:07:46.728831Z",
          "shell.execute_reply": "2025-05-21T12:07:47.101868Z"
        },
        "id": "lEqfZ824WNXr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "admissions = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/ADMISSIONS.csv\")\n",
        "patients = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/PATIENTS.csv\")\n",
        "diagnoses = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/DIAGNOSES_ICD.csv\")\n",
        "\n",
        "# Show column names\n",
        "print(\"ADMISSIONS columns:\", admissions.columns.tolist())\n",
        "print(\"PATIENTS columns:\", patients.columns.tolist())\n",
        "print(\"DIAGNOSES columns:\", diagnoses.columns.tolist())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T12:07:47.103586Z",
          "iopub.execute_input": "2025-05-21T12:07:47.104009Z",
          "iopub.status.idle": "2025-05-21T12:07:47.161419Z",
          "shell.execute_reply.started": "2025-05-21T12:07:47.103976Z",
          "shell.execute_reply": "2025-05-21T12:07:47.159976Z"
        },
        "id": "ada0mgPoWNXw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load datasets\n",
        "admissions = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/ADMISSIONS.csv\")\n",
        "patients = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/PATIENTS.csv\")\n",
        "diagnoses = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/DIAGNOSES_ICD.csv\")\n",
        "\n",
        "# Ensure lowercase columns\n",
        "admissions.columns = admissions.columns.str.lower()\n",
        "patients.columns = patients.columns.str.lower()\n",
        "diagnoses.columns = diagnoses.columns.str.lower()\n",
        "\n",
        "# Merge\n",
        "df = pd.merge(admissions, patients, on='subject_id', how='inner')\n",
        "\n",
        "# Convert to datetime\n",
        "df['admittime'] = pd.to_datetime(df['admittime'], errors='coerce')\n",
        "df['dob'] = pd.to_datetime(df['dob'], errors='coerce')\n",
        "\n",
        "# Drop rows with missing/invalid dates\n",
        "df = df.dropna(subset=['admittime', 'dob'])\n",
        "\n",
        "# Remove date outliers to prevent overflow\n",
        "df = df[(df['dob'].dt.year >= 1900) & (df['dob'].dt.year <= 2025)]\n",
        "\n",
        "# Calculate admit age safely\n",
        "df['admit_age'] = (df['admittime'] - df['dob']).dt.total_seconds() / (365.25 * 24 * 3600)\n",
        "df['admit_age'] = df['admit_age'].clip(lower=0, upper=120)\n",
        "\n",
        "# Emergency admission label\n",
        "df['is_emergency'] = df['admission_type'].apply(lambda x: 1 if x == 'EMERGENCY' else 0)\n",
        "\n",
        "# EDA plots\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.countplot(data=df, x='admission_type', order=df['admission_type'].value_counts().index)\n",
        "plt.title(\"Admission Types\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.kdeplot(data=df, x='admit_age', hue='admission_type', common_norm=False, fill=True)\n",
        "plt.title(\"Age Distribution by Admission Type\")\n",
        "plt.xlabel(\"Age at Admission\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(data=df, x='gender')\n",
        "plt.title(\"Gender Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(data=df, x='gender', y='is_emergency')\n",
        "plt.title(\"Emergency Admission Rate by Gender\")\n",
        "plt.ylabel(\"Proportion Emergency\")\n",
        "plt.show()\n",
        "\n",
        "# Join number of diagnoses per admission\n",
        "diag_counts = diagnoses.groupby('hadm_id').size().reset_index(name='num_diag')\n",
        "df = pd.merge(df, diag_counts, on='hadm_id', how='left')\n",
        "df['num_diag'] = df['num_diag'].fillna(0)\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "sns.histplot(df['num_diag'], bins=30, kde=True)\n",
        "plt.title(\"Number of Diagnoses per Admission\")\n",
        "plt.xlabel(\"Number of Diagnoses\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "sns.boxplot(data=df, x='is_emergency', y='num_diag')\n",
        "plt.title(\"Diagnoses Count by Emergency Admission Status\")\n",
        "plt.xlabel(\"Is Emergency\")\n",
        "plt.ylabel(\"Number of Diagnoses\")\n",
        "plt.show()\n",
        "\n",
        "df['gender_enc'] = df['gender'].map({'M': 1, 'F': 0})\n",
        "corr_features = df[['admit_age', 'num_diag', 'is_emergency', 'gender_enc']]\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(corr_features.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title(\"Feature Correlation\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T12:07:47.163071Z",
          "iopub.execute_input": "2025-05-21T12:07:47.163332Z",
          "iopub.status.idle": "2025-05-21T12:07:50.20396Z",
          "shell.execute_reply.started": "2025-05-21T12:07:47.163309Z",
          "shell.execute_reply": "2025-05-21T12:07:50.203006Z"
        },
        "id": "h0ey-srWWNX1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# 1. Import Libraries\n",
        "# ======================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import lightgbm as lgb\n",
        "import shap\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "shap.initjs()\n",
        "\n",
        "# ======================\n",
        "# 2. Load Datasets\n",
        "# ======================\n",
        "admissions = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/ADMISSIONS.csv\")\n",
        "patients = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/PATIENTS.csv\")\n",
        "diagnoses = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/DIAGNOSES_ICD.csv\")\n",
        "labs = pd.read_csv(\"/kaggle/input/mimiciii/mimic-iii-clinical-database-demo-1.4/LABEVENTS.csv\")\n",
        "\n",
        "# Standardize column names\n",
        "admissions.columns = admissions.columns.str.lower()\n",
        "patients.columns = patients.columns.str.lower()\n",
        "diagnoses.columns = diagnoses.columns.str.lower()\n",
        "labs.columns = labs.columns.str.lower()\n",
        "\n",
        "# ======================\n",
        "# 3. Merge & Feature Engineering\n",
        "# ======================\n",
        "df = pd.merge(admissions, patients, on='subject_id', how='inner')\n",
        "\n",
        "# Convert date columns\n",
        "df['admittime'] = pd.to_datetime(df['admittime'], errors='coerce')\n",
        "df['dischtime'] = pd.to_datetime(df['dischtime'], errors='coerce')\n",
        "df['dob'] = pd.to_datetime(df['dob'], errors='coerce')\n",
        "\n",
        "# Drop invalid dates\n",
        "df = df.dropna(subset=['admittime', 'dob'])\n",
        "\n",
        "# Keep plausible DOB range\n",
        "df = df[(df['dob'].dt.year >= 1900) & (df['dob'].dt.year <= 2200)]\n",
        "\n",
        "# Emergency admission label\n",
        "df['emergency_label'] = df['admission_type'].apply(lambda x: 1 if x == 'EMERGENCY' else 0)\n",
        "\n",
        "# Age at admission\n",
        "df['admit_age'] = (df['admittime'] - df['dob']).dt.total_seconds() / (365.25 * 24 * 3600)\n",
        "df['admit_age'] = df['admit_age'].clip(lower=0, upper=120)\n",
        "\n",
        "# Length of stay (in days)\n",
        "df['length_of_stay'] = (df['dischtime'] - df['admittime']).dt.total_seconds() / (3600 * 24)\n",
        "df['length_of_stay'] = df['length_of_stay'].clip(lower=0)\n",
        "\n",
        "# Admission month and season\n",
        "df['admit_month'] = df['admittime'].dt.month\n",
        "df['season'] = df['admit_month'] % 12 // 3 + 1\n",
        "\n",
        "# Time of day (night or not)\n",
        "df['hour'] = df['admittime'].dt.hour\n",
        "df['is_night'] = df['hour'].apply(lambda x: 1 if (x < 7 or x > 20) else 0)\n",
        "\n",
        "# Diagnosis count\n",
        "diag_count = diagnoses.groupby('hadm_id').size().reset_index(name='num_diag')\n",
        "df = pd.merge(df, diag_count, on='hadm_id', how='left')\n",
        "df['num_diag'].fillna(0, inplace=True)\n",
        "\n",
        "# Lab event count\n",
        "lab_count = labs.groupby('hadm_id').size().reset_index(name='num_labs')\n",
        "df = pd.merge(df, lab_count, on='hadm_id', how='left')\n",
        "df['num_labs'].fillna(0, inplace=True)\n",
        "\n",
        "# Encode gender\n",
        "df['gender'] = LabelEncoder().fit_transform(df['gender'])\n",
        "\n",
        "# ======================\n",
        "# 4. Prepare Data\n",
        "# ======================\n",
        "features = [\n",
        "    'gender', 'admit_age', 'num_diag', 'num_labs',\n",
        "    'length_of_stay', 'season', 'is_night'\n",
        "]\n",
        "\n",
        "X = df[features]\n",
        "y = df['emergency_label']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, stratify=y, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights_dict = {i: class_weights[i] for i in np.unique(y_train)}\n",
        "\n",
        "# ======================\n",
        "# 5. Train Optimized LightGBM Model\n",
        "# ======================\n",
        "params = {\n",
        "    'num_leaves': [31, 50, 70],\n",
        "    'max_depth': [-1, 10, 20],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'n_estimators': [100, 200, 500],\n",
        "    'subsample': [0.7, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.7, 0.9, 1.0],\n",
        "}\n",
        "\n",
        "lgb_est = lgb.LGBMClassifier(random_state=42, class_weight=class_weights_dict)\n",
        "search = RandomizedSearchCV(\n",
        "    lgb_est, param_distributions=params, n_iter=30,\n",
        "    cv=3, scoring='roc_auc', verbose=1, n_jobs=-1\n",
        ")\n",
        "search.fit(X_train, y_train)\n",
        "model = search.best_estimator_\n",
        "\n",
        "# ======================\n",
        "# 6. Predict & Evaluate\n",
        "# ======================\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "print(f\"AUC Score: {roc_auc_score(y_test, y_prob):.4f}\")\n",
        "\n",
        "# ======================\n",
        "# 7. Feature Importance\n",
        "# ======================\n",
        "lgb.plot_importance(model, importance_type='gain', figsize=(10, 6))\n",
        "plt.title(\"LightGBM Feature Importance (Gain)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ======================\n",
        "# 8. SHAP Explainability\n",
        "# ======================\n",
        "explainer = shap.Explainer(model, X_train)\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "# SHAP summary\n",
        "shap.summary_plot(shap_values, X_test)\n",
        "\n",
        "# SHAP waterfall plot for first test case\n",
        "shap.plots.waterfall(shap_values[0])\n",
        "\n",
        "# ======================\n",
        "# 9. Correlation Heatmap\n",
        "# ======================\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(X.corr(), annot=True, cmap='coolwarm')\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T12:07:50.204764Z",
          "iopub.execute_input": "2025-05-21T12:07:50.205082Z",
          "iopub.status.idle": "2025-05-21T12:08:19.12259Z",
          "shell.execute_reply.started": "2025-05-21T12:07:50.205051Z",
          "shell.execute_reply": "2025-05-21T12:08:19.121673Z"
        },
        "id": "ucYRx0FzWNX5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Define thresholds from 0.1 to 0.9\n",
        "thresholds = np.arange(0.1, 0.91, 0.05)\n",
        "f1_scores = []\n",
        "\n",
        "# Compute F1 score at each threshold\n",
        "for threshold in thresholds:\n",
        "    y_pred_thresh = (y_prob >= threshold).astype(int)\n",
        "    f1 = f1_score(y_test, y_pred_thresh)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Plot F1 score vs. Threshold\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(thresholds, f1_scores, marker='o', linestyle='-', color='darkgreen')\n",
        "plt.title('F1 Score vs Classification Threshold')\n",
        "plt.xlabel('Threshold')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.xticks(thresholds)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T12:08:19.123588Z",
          "iopub.execute_input": "2025-05-21T12:08:19.123867Z",
          "iopub.status.idle": "2025-05-21T12:08:19.394768Z",
          "shell.execute_reply.started": "2025-05-21T12:08:19.123834Z",
          "shell.execute_reply": "2025-05-21T12:08:19.3939Z"
        },
        "id": "e9pIqzNeWNX_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "# Define thresholds\n",
        "thresholds = np.arange(0.1, 0.91, 0.05)\n",
        "\n",
        "# Initialize list to collect metrics\n",
        "metrics_list = []\n",
        "\n",
        "# Compute precision, recall, f1 for each threshold\n",
        "for threshold in thresholds:\n",
        "    y_pred_thresh = (y_prob >= threshold).astype(int)\n",
        "    precision = precision_score(y_test, y_pred_thresh)\n",
        "    recall = recall_score(y_test, y_pred_thresh)\n",
        "    f1 = f1_score(y_test, y_pred_thresh)\n",
        "\n",
        "    metrics_list.append({\n",
        "        'Threshold': round(threshold, 2),\n",
        "        'Precision': round(precision, 4),\n",
        "        'Recall': round(recall, 4),\n",
        "        'F1-Score': round(f1, 4)\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "metrics_df = pd.DataFrame(metrics_list)\n",
        "\n",
        "# Display the table\n",
        "print(\"📊 Precision, Recall, F1-Score at Various Thresholds:\")\n",
        "print(metrics_df.to_string(index=False))\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T12:08:19.39578Z",
          "iopub.execute_input": "2025-05-21T12:08:19.396075Z",
          "iopub.status.idle": "2025-05-21T12:08:19.488752Z",
          "shell.execute_reply.started": "2025-05-21T12:08:19.396045Z",
          "shell.execute_reply": "2025-05-21T12:08:19.48778Z"
        },
        "id": "m_UQ_EwWWNYD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute ROC curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
        "auc_score = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {auc_score:.4f}\", color='darkorange', linewidth=2)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve (Receiver Operating Characteristic)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T12:08:19.489713Z",
          "iopub.execute_input": "2025-05-21T12:08:19.490398Z",
          "iopub.status.idle": "2025-05-21T12:08:19.715309Z",
          "shell.execute_reply.started": "2025-05-21T12:08:19.490371Z",
          "shell.execute_reply": "2025-05-21T12:08:19.714373Z"
        },
        "id": "IxesC-txWNYJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"✅ ROC AUC Score: {auc_score:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T12:08:19.716243Z",
          "iopub.execute_input": "2025-05-21T12:08:19.716526Z",
          "iopub.status.idle": "2025-05-21T12:08:19.721389Z",
          "shell.execute_reply.started": "2025-05-21T12:08:19.716493Z",
          "shell.execute_reply": "2025-05-21T12:08:19.72067Z"
        },
        "id": "QqxVEprFWNYO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "labels = ['Non-Emergency', 'Emergency']\n",
        "\n",
        "# Display as heatmap\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T12:08:19.723433Z",
          "iopub.execute_input": "2025-05-21T12:08:19.723735Z",
          "iopub.status.idle": "2025-05-21T12:08:19.928812Z",
          "shell.execute_reply.started": "2025-05-21T12:08:19.723706Z",
          "shell.execute_reply": "2025-05-21T12:08:19.927983Z"
        },
        "id": "YZt163xQWNYS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confusion Matrix (Raw Values):\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-21T12:08:19.929682Z",
          "iopub.execute_input": "2025-05-21T12:08:19.929958Z",
          "iopub.status.idle": "2025-05-21T12:08:19.934956Z",
          "shell.execute_reply.started": "2025-05-21T12:08:19.929913Z",
          "shell.execute_reply": "2025-05-21T12:08:19.934212Z"
        },
        "id": "-EabVxCbWNYV"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}